\section{Limitations}
\label{sec:limitations}

CLIP-CC-Bench's dataset of 200 movie clips with expert annotations provides focused evaluation but limits generalizability. The scale constrains statistical power, while the narrative film domain excludes instructional, surveillance, and user-generated content. Our English-only scope and proper noun elimination create controlled but potentially artificial evaluation conditions. Single reference descriptions cannot capture all valid descriptive perspectives.

Our embedding-based evaluation methodology, while effective at capturing holistic semantic alignment, requires more sophisticated scoring mechanisms. Current embedding models excel at matching overall semantic coherence but lack sensitivity to critical dimensions of video understanding: (1) precise content alignment and fine-grained detail accuracy, (2) detection of missing content and hallucinated details, (3) identification of major omitted events or entities, and (4) temporal ordering of narrative elements. These limitations prevent our current framework from fully assessing whether VLMs accurately describe all depicted events in their correct sequential order versus merely capturing the general thematic essence. Future work should develop evaluation metrics that simultaneously assess overall narrative coherence, local semantic precision, and temporal event ordering.

Heterogeneous frame processing (8-600 frames across models) introduces comparison confounds despite reflecting realistic deployment scenarios. The ensemble approach with five embedding models provides robustness but increases computational overhead, potentially limiting accessibility for resource-constrained research.

These constraints suggest future directions: expanded scale and domains, multiple references, cross-linguistic frameworks, temporal-aware evaluation metrics, and efficiency benchmarks. Nevertheless, CLIP-CC-Bench advances VLM evaluation through rigorous ensemble methodology, with insights about architecture family performance and coarse-fine granularity gaps extending beyond these limitations.
